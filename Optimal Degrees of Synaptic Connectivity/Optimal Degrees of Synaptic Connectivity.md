# Optimal degrees of synaptic connectivity

* **Authors:** Ashok Litwin-Kumar, Kameron Decker Harris, Richard Axel, Haim Sompolinsky, L.F. Abbott
* **Journal:** Neuron 93
* **Date:** March 2017

## Introduction 
* In this study, the authors explore the role synaptic connectivity in high-dimensional representation of input data. Specifically, they note two examples of sparse connectivity to an overcomplete representation: the mushroom body in *Drosophila* and the cerebellar cortex. 
* They use theoretical results to assess what impact the degree of synaptic connectivity, balance of excitation and inhibition, and synaptic weight distribution has on the ability of a large neural representation to support associative learning. 
* Their main result, in my eyes: there's a tradeoff between high-dimensional representation and learning. If you want your high-dimensional representation to explore all subspaces, then you're better off having sparse connectivity with large expansion. If instead you want to do supervised learning, you're better off having very dense connectivity. 

## Results
* **Model:** Their model, pictured in **Figure 1a** below, consists of $M$ neurons that receive input (mixed layer) from $N$ channels (input layer). They assume neurons in the input layer carry no redundant information. Furthermore, each neuron in the mixed layer allows for $K$ excitatory synaptic connections and there is one global inhibitory neuron. They further assume that $M>N$ (we have overcompleteness) and define the expansion ratio as $M/N$ (the degree of overcompleteness). Lastly, there is some readout neuron that has access to the mixed layer. <center>![litwin_kumar_fig1.png](resources/0E0D40AB1E6CD9B156E6AE484BE7AD5A.png =422x375)<br><b>Figure 1</b></center>
* The two main models they make reference to are the mushroom body in Drosophila (**Figure 1b**) and the cerebellar cortex (**Figure 1c**). In the former, there are projection neurons in the antennal lobe (input layer) which synapse onto the Kenyon cells (the mixed layer) which are inhibited by the anterior paired lateral (APL) neuron and read out by Mushroom body output neuron (MBON). In the latter, the mossy fibers (input layer) project onto granule cells (the mixed layer) which are inhibited by Golgi cells and read out by Purkinje cells. 

### Heterogeneous Responses via Random Connectivity
* They assume that each neuron in the mixed layer would like to receive a distinct set of inputs, so that there's less redundancy. A simple calculation can see how likely this is, assuming the input neurons are randomly assigned to the mixed layer neurons. 
* Under these assumptions, $K$, the synaptic degree, should be chosen such that there's a high probability (they arbitrarily choose 95%) that each of the inputs is distinct. The total number of distinct inputs is given by ${N \choose K}$, and we have $M$ draws from this pool (for each of the mixed layer neurons). In order to guarantee that 95% of the time, these $M$ draws are distinct, $K$ should be chosen to be $K^* = 7$ for Drosophila and $K^* = 4$ for cerebellum. Both these predictions match experimental results.
* While the above result is nice, it's not robust enough. Distinct input patterns are good, but the input patterns can be overlapping (for example, the inputs to two mixed layer neurons are all the same except one). To handle this, the authors concoct a measure called the dimension, $$\text{dim}(\mathbf{x}) = \frac{\left(\sum_{i=1}^M \lambda_i\right)^2}{\sum_{i=1}^M \lambda_i^2}$$ where $\lambda_i$ are the eigenvalues of the covariance matrix for the input, $\mathbf{x} = (x_1, x_2, \ldots, x_M)$. The dimension is a measure of how many subspaces the data fill and how similarly they do so. For example, if the covariance is isotropic in all subspaces, then the dimension will be equal to $M$. If it fill $m$ subspaces isotropically, the dimension will be $m$. 
* **Linear case:** First, they considered the case where each of the $M$ mixed layer  neurons linearly combines some subset of the $N$ inputs. The dimension of the synaptic currents, $\mathbf{h}$, is given by $$\text{dim}(\mathbf{h}) \approx \frac{N}{1 + N/M + (K-1)^2/N}.$$ Some key points here: (1) the dimension cannot be higher than $N$, because the inputs are linearly combined; (2) the synaptic degree $K$ can only reduce the dimension (which is bad); thus, $K=1$ is the optimal network in this case; (3) as $K$ approaches $N$, the dimension approaches 1 (makes sense - each neuron in the mixed layer receives *all* of the inputs, so that none of them are linearly independent, leaving one subspace to fill).
* **Nonlinear Case:** Next, they considered a nonlinearity attached to the linear mixing. They chose the nonlinearity $\mathbf{m} = \Theta(\mathbf{h}-\boldsymbol{\theta})$, where $\mathbf{h}$ is the output of the linear mixing. Thus, each neuron is separately thresholded by a given value, such that it's active with probability $f$ (called the coding level). Under these assumptions, they find a dimension equal to $$\text{dim}(\mathbf{m}) = \frac{1}{1/M + \langle \rho_{ij}\rangle^2 + \text{Var}(\rho_{ij})},$$ where $\rho_{ij}$ is equal to the correlation coefficient between $m_i$ and $m_j$ over the input patterns (which they assume are standard Gaussians). What this dimension seems to be telling us is that it wants to be equal to $M$, but the correlations prevent this from occurring. 
* **Inhibition:** The previous results seem to imply that correlations are harmful to the network. Past work has demonstrated that inhibition can decorrelate a network, so they try adding an inhibitory neuron that is connected to all the mixed layer neurons. The inhibitory neuron inhibits all mixed-layer neurons in proportion to their input. 
* They summarize these results in **Figure 2**, below. **Figure 2A** shows a three dimensional space, $\mathbf{x} = (x_1, x_2, x_3)$, with both a high dimensional distribution and a low dimension distribution. Notice that the green distribution is lower dimension, because it occupies one subspace preferentially. 
* **Figure 2B** shows the dimension (normalized by $N$) for the linear (gray) and nonlinear (black) cases as a function of the expansion ratio $M/N$. They're shown for the value of $K$ that maximizes the dimension (so $K=1$ for the linear case). Increasing the expansion ratio will always increase the dimension, but eventually it will saturate. For the linear case, it will saturate to $N$ (1 on the graph; this makes sense).
* **Figure 2C** shows the dependence of the dimension (normalized) on $K$ for various expansion ratios. Thus, increasing expansion ratio increases the dimension, as we already know. However, increasing $K$ for sufficiently large expansion ratios causes the dimension to peak and then decrease. The dimension is larger for the nonlinear case, but this is emphasized for larger expansion ratios and smaller $K$.<center>![litwin_kumar_fig2.png](resources/31E850204D1722D6BA2BBBA6C3FF5EF5.png =428x463)<br><b>Figure 2</b></center>
* Lastly, **Figure 2D** shows the effects of inhibition. Inhibition is indicated by red, while the nonlinear and linear cases are once again shown by black and grey. Increasing $K$ for the case of inhibition will increase the dimension for very large $K$, and it will eventually approach its largest value at $K=N/2$. 
* The moral of the story here is that these networks can represent high-dimensional structure by just taking a few synaptic inputs. When you add inhibition, you can go even more high-dimensional by taking large amounts of synaptic inputs. There seems to be a connection between sparse and dense coding here. 

### Optimal Connectivity for Random Representations under Resource Constraints
* Next, they examined whether the observed synaptic connectivity could be explained by *constraints* on the system. Specifically, if my system can have no more than $S$ synaptic connections, what's the choice of $K$ (synaptic degree) and $M$ (number of mixed neurons) that maximizes the dimension of the system? They explored this question using both the mushroom body and cerebellum.
* In **Figure 3A**, they plot the impact $K$ has on the (normalized) dimension for a given coding level ($f = 0.1$) and number of inputs $N$. They plot their results for both the case of inhibition (red) and no inhibition (black). They find that their prediction for the mushroom body ($K = 8$, close the observed $K=7$). In **Figure 3B**, they plot the same figure but for cerebellum. Their inhibition/no inhibition curves are almost exactly the same because for their $N$, which is very large, small $K$ implies that there won't be much overlap in the inputs and thus no need for decorrelating input via inhibition. At any rate, their predicted value of $K$ is $K=4$, in agreement with the experiments. <center>![litwin_kumar_fig3.png](resources/59759FA1DE55C4D0BE26DFB75FE2FD4D.png =430x388)<br><b>Figure 3</b></center>
* In **Figure 3C** and **Figure 3D**, they plot the optimal $K$ for a variety of coding strengths. Their point here is that optimal $K$ does not change much as a function of $f$ (over two/three orders of magnitude for $f$, $K$ hardly changes by more than 3 or 4).

### Heterogeneous Synaptic Weights
* In the previous case, they only added up the synaptic currents to obtain the input for the mixed layer nonlinearity. But what if you apply different weights to each input? Here, they draw synaptic weights from a distribution with mean $\langle w \rangle$ and $\text{Var}(w)$. In this case, with very large $M$ and $N$, we have a dimension of $$\text{dim}(\mathbf{h}) = \frac{N}{1 +\frac{(K-1)^2}{N} \left(\frac{\langle w\rangle^2}{\langle w \rangle^2 + \text{Var}(w)}\right)^2}.$$Notice that increasing the variance, or the heterogeneity of the weights, will increase the dimension. 
* After this, they add global inhibition. **Figure 4A** below shows the normalized dimension as a function of $K$ for heterogeneous weights (drawn from a log-normal). Notice that adding inhibition only modeslty increases the dimension (compared to **Figure 2D**). To explore why this is the case, they find that the correlations between the inputs will increase when the weights are made more heterogeneous. They claim that the inhibition acts as an extra source of correlated input, but that it can be averaged out in the presence of multiple inhibitory neurons.  <center>![litwin_kumar_fig4.png](resources/274D06B18C4BEA84D8726003298806C8.png =595x448)<br><b>Figure 4</b></center>
* Thus, in **Figure 4B**, they show the effects of having more inhibitory neurons. Increasing the number increases the dimension and also increases the value of $K$ at which the dimension is maximized. 
* They propose another reason that inhibition might be a good thing. If the input signals also follow some coding level (for example, they follow a truncated Gaussian), then it's difficult to pick a threshold that will work for both low input coding levels and high input coding levels. The dynamic range of the mixed layer becomes too low. But if we add inhibition (just one global inhibitory neuron), then we can maintain a constant coding level more easily. This is shown in **Figure 4C**, which plots the mixed coding level as a function of the input coding level. In the case of inhibition, we can maintain the coding level of the mixed layer (but without it, our mixed layer can't handle a wide array of input codes). 
* Thus, the propose two uses of inhibition for random expansions: normalization and decorrelation. Normalization is what we discussed in the previous bullet point; it'll increase the dynamic range of the neurons. Meanwhile, decorrelation is beneficial for the dimension as discussed previously.
* Lastly, **Figure 4D** and **Figure 4E** show how the dimension behaves as a function of $K$ when the synaptic weights are fit to the weight distribution for each of the mushroom body and cerebellum, rather than neocortex. Here, they find that the optimal values for synaptic degree match more closely with anatomy. 

### Local connectivity in Cerebellar Cortex
* It's well known that the connectivity in Drosophila seems to be random. But what about in cerebellum? It's not as well understood, but there's a model out there that supposes that the mossy fibers preferentially synapse onto nearby granule cells (shown on the right side of **Figure 5A**). This model is in contrast with the random wiring model (shown on the left side of **Figure 5A**).
* We might expect that, in the local model, since nearby neurons are receiving similar input, their responses will be more dependent on each other and thus the covariance will occupy subspaces in the mixed layer space less isotropically. Thus, the dimension should decrease, which might change their predictions. Indeed, there is some substance to this concern: **Figure 5B** shows the probability of two granule cells having a certain number of shared inputs for the random and local models. Notice that the local model has a higher probability of having shared inputs.  <center>![litwin_kumar_fig5.png](resources/DF8959249C44BB1DE52C58F99B2B2F1C.png =420x372)<br><b>Figure 5</b></center>
* They repeat their dimension calculation for the local model, and find that the dimension does indeed decrease. The $K$ that produces maximal dimension, however, does *not* change, supporting their major claim (**Figure 5C**). 

### Classification of Mixed-Layer Responses
* Thus far, their work has largely been theoretical. In this section, they aim to show that their measure of dimension is meaningful in the context of classification. They begin by pairing up each combination of input signals with a valence (representing, for example, aversive and appetitive stimuli). Thus, they come up with a fully-connected classifier that determines the valence of a given mixed-level representation with the weights $\mathbf{w} = \sum_{\mu=1}^P(\mathbf{m}^{\mu}-f)v^{\mu}$.  
* To test the strength of their classifier, they measure its performance on the very same input patterns, but corrupted with noise.  Their measure of corruption is given by $\Delta = d/(2f(f-1))$, where $\Delta = 0$ for no noise and $\Delta = 1$ for very large noise. I'm not sure why $\Delta = 1$  for large noise. At any rate, their key result is that the signal to noise ratio of their decoder is proportional to the dimension: $$\text{SNR} = \frac{\text{dim}(\mathbf{m}) \cdot (1-\Delta)^2}{P}.$$ <center>![litwin_kumar_fig6.png](resources/8C5E9D5AEE037C7AE9EEB7345A2A231C.png =427x536)<br><b>Figure 6</b></center>
* For a fixed coding level and Gaussian noise in the input layer, $\Delta$ is going to be independent of the synaptic degree, which is shown in **Figure 6B** above. However, a more reasonable model may be to treat the inputs as binary rather than Gaussian (to model spikes). If they do this, $\Delta$ does depend on synaptic degree, and they find the smallest $\Delta$ arises with lower synaptic degree, implying sparse connectivity. 
* They further show in **Figure 6C** the performance of their classifier for the Gaussian and Binary patterns in the cases with and without inhibition. They find that when there's inhibition, lower synaptic degree leads to better performance for the classifier. They reason this as follows: when there's a low coding level, the mixed layer neurons are sensitive to noise, and if each one gets less synaptic inputs, then some of the mixed layer neurons will not feel the effects of noise as strongly. 

### Learned Mixed-Layer Representations
* Lastly, they tested whether unsupervised learning could improve classification. They hypothesize that this is particularly important in the case where the input layer and mixed layer neurons are not normalized (their variances and coding levels are homogeneous). Thus, they implemented a plasticity rule that bidirectionally adjusts synaptic weights based on recent activity and furthermore adjusts the excitability of the mixed layer neurons to maintain a desired coding level.  Basically, they used unsupervised learning to mess with parameters to guarantee that their network maintained sparse activity. **Figure 7A**, below, demonstrates that such an unsupervised procedure lowers the error rate for all synaptic degrees.<center>![litwin_kumar_fig7.png](resources/CB1DF38C87170C92DB15A9AEC0F93887.png =586x235)<br><b>Figure 7</b></center>
* But what about doing supervised learning on the parameters of the mixed-layer? First, they try to do supervised learning by matching the mixed-layer with random "target patterns." Their results are shown by the blue curve in **Figure 7B**, above. They only achieve enhanced performance once the synaptic degree is very large. If they incorporate information about valence in the target patterns, however, they find that the error increases greatly (cyan curve).
* Unfortunately, it seems as if these benefits come with a decrease in dimension, shown in **Figure 7C**. Thus, there appears to be a tradeoff between high-dimensional representation and minimizing classification error for known patterns. Of course, this is a moot point if we're in the regime of sparse connectivity: these effects are not felt until $K$ is at least a couple orders of magnitude. 

## Discussion
In their words: "the sparse connectivity observed in the cerebellar granule-cell layer and analogous structures is well suited for producing high-dimensional representations that can be read out by densely connected output neurons." 

### Expansion via Sparse Connectivity in Neural Systems
They emphasize that their results support the notion that sparse connectivity, or low $K$ is the most important factor in maximizing dimension. While a low coding level can come into play (in other words, sparse *activity*), it's not sufficient to guarantee high dimension. 

### The Cerebellar Granule-Cell Representation
They draw similarities of their model to observations in cerebellar cortex: for example, their model has the same predictions for random connectivity or local connectivity; furthermore, plasticity in the mossy-fibers is similar to the plasticity they showed above.

### Neural Representations for Associative Learning
They mention that their results do not take into consideration correlations within the inputs of their model. Furthermore, their model neglects the time domain, but they expect their qualitative results to hold.

### Learning in Cerebellum-like and Cerebrocortical Systems
Their results on associative learning are consistent with the observation that both task-relevant variables and reward are represented in higher neocortical regions.